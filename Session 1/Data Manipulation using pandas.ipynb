{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Hands-on Workshop series in Machine Learning\n",
    "### Session 1: Data Manipulation using pandas\n",
    "\n",
    "### Meet the Instructor:\n",
    "Aashita Kesarwani  \n",
    "Current job: Scientific Computing  and Data Science Specialist at Harvey Mudd College  \n",
    "Background:  \n",
    "- PhD in Mathematics from Tulane University (Number Theory)\n",
    "- Undergraduate from IIT (Indian Institute of Technology) in Applied Mathematics    \n",
    "- Visiting AI Researcher at [deepkapha.ai](https://www.linkedin.com/company/digitalis-kapha-b-v-/) in 2019\n",
    "- [Open source contributor](https://pypi.org/user/Aashita/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please:\n",
    "- feel free to interrupt to ask questions (if participating remotely, type in the chat window or raise your hand to speak)\n",
    "- feel free to ask for help while working on problems \n",
    "- feel free to Google and/or use any available tools (including AI-assisted programs such as [chatGPT](https://chat.openai.com/chat) or Github Copilot) while working on problems\n",
    "\n",
    "If the Jupyter notebook or Python is not running in your laptop or you do not have all the required packages installed, you can use [Google Colab](https://colab.research.google.com/). Colab runs on the cloud in a web browser on Google machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is machine learning?\n",
    "- Learning from data without explicit programming.\n",
    "\n",
    "##### How to approach a problem? \n",
    "- Data exploration and feature engineering \n",
    "- Model building, tuning and testing \n",
    "    \n",
    "#### Topics to be covered today (Data manipulation using `pandas`)\n",
    "- A brief overview of Jupyter Notebook\n",
    "- Pandas dataframes as the data structure for datasets\n",
    "- Slicing dataframes using conditionals as well as iloc and loc methods.\n",
    "- Statistical summary and exploration of dataframes\n",
    "- Basic plots\n",
    "- Feature engineering:\n",
    "    - Detecting and filling missing values in the dataframes\n",
    "    - Creating new features; using regular expressions for data extraction\n",
    "    - Dropping rows/columns; replacing values of a column using a dictionary\n",
    "- Merging columns from different datasets (Optional)\n",
    "\n",
    "Today's session is meant to ease you into the very first step of the machine learning project - cleaning and exploring the data. The machine learning algorithms will be introduced from the next session, when we will start building models for classification tasks.\n",
    "\n",
    "##### Structure of the session:\n",
    "\n",
    "The notebook is divided into the following sections:  \n",
    "\n",
    "0. Preliminaries  \n",
    "1. Slicing rows and columns from the dataframe\n",
    "2. Exploring the dataset (45 min exercise session)\n",
    "3. Feature Engineering: Creating a new column for the titles of the passengers (30 min exercise session)\n",
    "4. Merging columns from different datasets (Optional) \n",
    "\n",
    "You will follow along with me in some of the sections and the rest are the exercises that you will work on in groups in Zoom breakout rooms.\n",
    "\n",
    "##### Note:\n",
    "* Solutions for all the exercises (including the ones in the follow-along section) will be uploaded in the same folder of the [Github repository](https://github.com/AashitaK/A-Hands-On-Workshop-In-Machine-Learning/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Preliminaries\n",
    "#### An overview of ***Jupyter Notebook***.\n",
    "Jupyter Notebook is the de facto standard in Data Science inspired by the concept of [literate programming](https://www-cs-faculty.stanford.edu/~knuth/lp.html) introduced by [Donald Knuth](https://amturing.acm.org/award_winners/knuth_1013846.cfm). \n",
    "\n",
    "It is composed of blocks that are called cells.\n",
    "\n",
    "There are two types of cells:\n",
    "* Code cells\n",
    "* Markdown cells (for text such as this cell itself)\n",
    "\n",
    "You can run the code within the cells (No need to use command line) by first selecting the cell and then using `Shift` + `Enter`. Another option is to use the `Run` button at the header at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 3\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key shortcuts using command mode\n",
    "Press `Esc` to activate the command mode:\n",
    "Shortcuts:\n",
    "* A: Insert cell above\n",
    "* B: Insert cell below\n",
    "* C: Copy \n",
    "* V: Paste \n",
    "* X: Cut \n",
    "* DD: Delete \n",
    "* M: Convert a cell to Markdown cell\n",
    "* Shift: Let's you select multiple cells at once that you can copy/cut/delete.\n",
    "\n",
    "To exit the command mode, simply press `Enter`. You need to first exit the command mode to run/edit the cell. \n",
    "\n",
    "Jupyter notebook allows Tab completion, so as to let you avoid typing the function and variable names. \n",
    "\n",
    "It also supports the help feature. \n",
    "- To get documentation about a function, you pass the name of the function inside `help()`.\n",
    "- To view help, you can also type the function name followed by `?`.\n",
    "- To get the source code of a function, type the function followed by a double question mark `??`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import median\n",
    "help(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A brief overview of Markdown:\n",
    "\n",
    "Q: What is markdown?\n",
    "\n",
    "A: Markdown is a  simple markup language that uses plain-text syntax and functions pretty similarly to HTML. \n",
    "\n",
    "\n",
    "Q: What are some style things I can do with it?\n",
    "\n",
    "# \\# Headers\n",
    "\n",
    "\n",
    "\\*\\*Bold text\\*\\* --> **Bold text**\n",
    "\n",
    "\n",
    "\n",
    "\\*Italics\\* --> *Italics*\n",
    "\n",
    "\n",
    "> \\> Block quotes\n",
    "\n",
    "Bulleted list:\n",
    "\n",
    "- \\- Item 1\n",
    "\n",
    "- \\- Item 2\n",
    "\n",
    "\n",
    "Horizontal divider\n",
    "\n",
    "Syntax: \\-\\-\\-\n",
    "\n",
    "---\n",
    "\n",
    "\\[Linked text\\](link url) --> [Linked text](https://en.wikipedia.org/wiki/Python_(programming_language))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\`Code snippets\\` --> `Code snippet`\n",
    "\n",
    "\n",
    "\n",
    "\\`\\`\\` \n",
    "\n",
    "Code block --> \n",
    "\n",
    "\\`\\`\\`\n",
    "\n",
    "```\n",
    "{\n",
    "Code block\n",
    "}\n",
    "```\n",
    "\n",
    "Supports $\\LaTeX$:\n",
    "\n",
    "\\frac{x^2+1}{3} --> $\\frac{x^2+1}{3}$ \n",
    "\n",
    "\n",
    "    \n",
    "</font>\n",
    "\n",
    "Embeds image:\n",
    "\n",
    "\\!\\[\\]\\(*Image Address*\\) --> ![](https://upload.wikimedia.org/wikipedia/commons/3/38/Jupyter_logo.svg)\n",
    "\n",
    "##### Markdown is used to style all the course materials, so it helps to have a little familiarity. \n",
    "\n",
    "As your Jupyter notebook can be exported in many formats, Markdown is a useful tool to learn for presenting your data analysis or machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Numpy Arrays\n",
    "\n",
    "***Q: What are the `numpy` arrays? Why do we need them?***\n",
    "\n",
    "`numpy` is one of the commonly used python modules/packages, which stands for numerical python. Numpy arrays are multidimensional arrays that are optimized for computing, especially for operations such as matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use python modules, we first need to import them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The following two modules matplotlib and seaborn are for plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Comment this if seaborn is not installed\n",
    "%matplotlib inline\n",
    "\n",
    "# The module re is for regular expressions\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Dataframes\n",
    "\n",
    "***Q: What are the*** `pandas` ***dataframes? Why do we need them? What is the crucial difference between numpy matrices and*** `pandas` ***dataframes?***\n",
    "\n",
    "Pandas: an excellent tool to work with datasets\n",
    "\n",
    "Dataframes: the central data structure of pandas library\n",
    "- Evolved out of tables\n",
    "- Most suitable for data manipulation tasks  \n",
    "\n",
    "Pandas is built on top of numpy. The crucial difference between numpy matrices and pandas dataframes is that the columns in a Dataframe can be of different datatypes such as numerical, categorical, textual, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) stored in the `csv` file as a dataframe using [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using Google Colab, the above will give you an error.\n",
    "\n",
    "You will have to first download the `titanic.csv` file from the [Github repository](https://github.com/AashitaK/A-Hands-on-Workshop-series-in-Machine-Learning/tree/master/Session%201/titanic) then manually upload it to Colab using: \n",
    "```python\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "```\n",
    "\n",
    "Then, load the file into pandas dataframe using `read_csv`:\n",
    "```python\n",
    "df = pd.read_csv('titanic.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out to be rather big dataset to display, we can comment the above cell by adding # in front of df and run it again to get rid of the output.\n",
    "\n",
    "Next, let's check the numbers of rows and columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the dataset consists of 891 rows and 12 columns.\n",
    "\n",
    "We use `head()` function to peek into the first 5 rows (or any number of rows by using `head(n)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Titanic dataset](https://www.kaggle.com/c/titanic) that we will explore today is sourced from a [Kaggle](https://www.kaggle.com/) beginner-level competition.  \n",
    "\n",
    "Goal of the competition: To apply the tools of machine learning to predict which passengers survived the Titanic tragedy.\n",
    "\n",
    "[Description for the columns](https://www.kaggle.com/c/titanic/data) is as follows.  \n",
    "\n",
    "|Variable|\tDefinition|\tKey|   \n",
    "|:---  |:--- |:---|\n",
    "|PassengerId| Passenger ID |\n",
    "|Survived| \tSurvival|\t0 = No, 1 = Yes |\n",
    "|Pclass\t|Ticket class|\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|Sex\t|Sex|\t\n",
    "|Age\t|Age in years\t|\n",
    "|SibSp\t|# of siblings / spouses aboard the Titanic\t|\n",
    "|Parch\t|# of parents / children aboard the Titanic\t|\n",
    "|Ticket\t|Ticket number\t|\n",
    "|Fare\t|Passenger fare\t|\n",
    "|Cabin\t|Cabin number\t|\n",
    "|Embarked\t|Port of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: What are the features? \n",
    "\n",
    "Features are nothing but the variables in our model or the columns in our dataset. For example, `PClass`, `Age`, `Sex`, `Fare`, etc. are features for this particular dataset.\n",
    "\n",
    "The final goal is to design a model to predict whether a passenger survives or not. \n",
    "* Which of the above features seem like important predictors? \n",
    "* How can you analyse the data in view of this objective?\n",
    "    \n",
    "Q: What is feature engineering?\n",
    "* Detecting and handling missing values\n",
    "* Encoding categorial features into numerical values\n",
    "* Creating new features from the existing ones\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecting rows and columns from the dataframe\n",
    "\n",
    "How do we select a column from the dataframe? Say, we want to select the *Name* column from the dataframe. \n",
    "\n",
    "Remember, we used square brackets for indexing lists, strings and numpy arrays in Python, for example `A[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not want all the rows in the output, we have used `head()` function at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we select **multiple columns**? Suppose we want to select the columns *Name, Sex* and *Age* from the dataframe. Hint: Use a list of columns inside the square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select **rows** by putting a certain **condition on a column**. Say, we want only those rows for which the gender is *'female'*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Sex\"] == \"female\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to retrieve only the female passengers traveling in the first class. Hint: Add another conditional `df['Pclass']==1` to the above code using the operator `&` and make sure to wrap the two conditionals with parenthesis `()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the number of passengers using the shape method which gives us both the number of columns and the number of rows. Write the code to count the number of female passengers traveling in the first class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `loc` and `iloc` methods\n",
    "So far, we have seen how to retrieve:\n",
    "* some select columns, or\n",
    "* certain rows based on conditionals. \n",
    "\n",
    "What if we want to slice off a portion of the dataframe with some specific rows **and** columns? We use `.loc[]` or `.iloc[]` methods for this purpose. \n",
    "* `.iloc[]` method is primarily integer position based and gets rows/columns at particular positions in the index (so it **only takes integers** as index). \n",
    "* `loc[]` method is label based and gets rows/columns with particular labels from the index. Thus, it can be used to **put conditions on rows and retrieve select columns simultaneously**.\n",
    "\n",
    "For example, we want to get the name and the survival information for all the adults above 70 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Age']>70, ['Name', 'Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve the **name, age and survival** information for all the **female passengers traveling in the first class**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iloc[]` method let us retrieve rows by passing sequence of indexes. For example, we can select the rows numbered 100th to 105th. The indexing works exactly like python lists and numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100:106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve every 100th row from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to retrieve the last 10 rows from the dataframe using `iloc[]` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Instructions for the exercise session:\n",
    "- There are two exercise sections (section 2 and 3) below and they are alloted 45 min and 30 min respectively.\n",
    "- The exercise involves new concepts not covered in the guided session above. Please feel free to ask questions and take help from me and/or your peers in the breakout room.\n",
    "- The hints are provided for the each of the exercises. The built-in functions to be used for them are provided with a clickable link to the user manual. \n",
    "- The exercise sessions are time-bound and you are encouraged to work in groups to speed things up! \n",
    "- If you finished a section early, move on to the next one. There is an optional section 4 at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring the dataset (45 min)\n",
    "\n",
    "Use [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function for numerical features (columns) to get a brief overview of the statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same as above for qualitative (non-numerical) features. Hint: Use `include=['O']` parameter in the [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Use the built-in pandas function to count the number of surviving and non-surviving passengers. Hint: Use [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) on the column `df['Survived']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a pie chart of the same using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('equal') \n",
    "plt.pie(df['Survived'].value_counts(), labels=('Died', \"Survived\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a bar chart for the survival rate among male and female passengers using `seaborn` which we imported above as `sns`. Here is [Seaborn cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Sex', y = 'Survived', data = df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the survival rate among passengers in each ticket class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the survival rate among both genders within the three ticket classes as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chart, do you think that the gender affect the chance of survival for all the three ticket classes equally? Or does it seem like gender's effect is more pronounced for a certain ticket class passengers than others? We plot the  point estimates and confidence intervals for each sub-category to see it more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(x='Sex', y='Survived', hue='Pclass', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the steeper slope for the second class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that gender and ticket class put together give more information about the survival chance than both of them separately. Please feel free to later explore other variables and combination of variables in depth in your own time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many children were on board? Hint: Use indexing on rows using conditional on the *Age* column and then the [`shape`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html) method to count the rows as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many of the children on board survived? Hint: Add another conditional for the *Survived* column to the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions [`isnull()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html) and [`sum()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) chained one after the other on the dataframe to find out the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detecting missing values** is an important first step in Feature Engineering, that is preparing the features (independent variables) to use for building the machine learning models. \n",
    "\n",
    "The next step is **handling those missing values**. An option is to drop the rows or columns that have some or a lot of missing values, but that also means discarding relevant information. Another option is to fill them with something appropriate. \n",
    "\n",
    "Discuss:\n",
    "1. What are the pros and cons of dropping the rows and/or columns with missing values?\n",
    "    - Should you drop none, all or some of the columns with missing values for this dataset in view of building the predictive model? \n",
    "    - Ditto for rows with missing values.\n",
    "3. If you consider filling the missing values, what are the possible options? \n",
    "    - Can you make use of other values in that column to fill the missing values? \n",
    "    - Can you make use of other values in that row as well as values in that column to fill the missing values \n",
    "4. Can the title in the name column be used for guessing a passengers' age based on the age values of other passengers with the same title?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most common port of embarkment? Hint: Check the frequency (counts) of each value in the Embarked column using the built-in function [`value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) as seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, there are missing values in the column for *Embarked*. Fill them with the most commonly occuring value. Hint: Use [`fillna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the missing values for the *Embarked* column is indeed filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, there are two options to fix this. One is to set `inplace` parameter in the `fillna()` function as `True` and another is to use assignment operator `=` as in `df = df.function()`. \n",
    "\n",
    "***Question***: Why is the `inplace` keyword False by default? This is true not just for `fillna()` but for most built-in functions in pandas. \n",
    "\n",
    "Answer: To facilitate method chaining or piping i.e. invoking multiple operations one after the other. For example, `df.isnull().sum()` used above. Chaining is more commonly used in pandas as compared to another programming style i.e. using nested function calls. Please read more [here](https://towardsdatascience.com/the-unreasonable-effectiveness-of-method-chaining-in-pandas-15c2109e3c69), if interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should remove the *Cabin* column from the DataFrame -- too many values are missing. Hint: Use [`drop()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) with appropriate value for the `axis` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the column is indeed dropped. If not, modify the code above accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the age of the oldest person on board? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the passenger information for the oldest person on board. Hint: Use [`loc[]`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method with [`idxmax()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.idxmax.html) for the Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Feature Engineering: Creating a new column for the titles of the passengers (30 min)\n",
    "\n",
    "The real-world datasets many-a-times contain useful information in the textual format. Text mining is an important area of data science and one of the most powerful tool is [regular expressions](https://www.gnu.org/software/sed/manual/html_node/Regular-Expressions.html) that are not specific to python, but have much wider applications.\n",
    "\n",
    "In this section, you are going to create a new feature for the titles of the passengers derived from their names using regular expressions. For that, let us first take a look at the passengers' names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:20, 'Name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice one of the identifying characteristics of the titles above are that they end with a period. Regular expressions are very useful in the process of such data extraction and we will use them using the python module `re` to extract the titles from the *Name* column. We will first use regular expressions characters to construct a pattern and then use built-in function `findall` for pattern matching.\n",
    "\n",
    "Some useful regular expression characters:\n",
    "- `\\w`: pattern must contain a word character, such as letters.\n",
    "- `[ ]`: pattern must contain one of the characters inside the square brackets. If there is only one character inside the square brackets, for example `[.]`, then the pattern must contain it.\n",
    "\n",
    "Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Braund, Mr. Owen Harris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! It returned a list instead of the string, so we use indexing to get the first element of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Braund, Mr. Owen Harris')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it on another name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"\\w\\w[.]\", 'Heikkinen, Miss. Laina')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we want a pattern that automatically detects the length of the title and returns the entire title.\n",
    "\n",
    "For regular expressions, \\+ is added to a character/pattern to denote it is present one or more times. For example, `\\w+` is used to denote one or more word characters. Fill in the regular expression in the below cell that will detect a period preceeded by one or more word characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"FILL HERE\", 'Heikkinen, Serget. Laina')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Miss.'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary: For pattern matching the titles using regular expressions:\n",
    "- First we make sure it contains a period by using `[.]`. \n",
    "- Secondly, the period must be preceeded by word characters (one or more), so we use `\\w+[.]`.\n",
    "\n",
    "Write a function `get_title` that takes a name, extracts the title from it and returns the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    title = \n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the function is working properly by running the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Futrelle, Misses. Jacques Heath (Lily May Peel) Dr.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Mrs.'`. Note: Make sure that the funtion returns a string and not a list. Please modify the above function accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_title('Simonius-Blumer, Col. Oberst Alfons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `'Col.'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named Title and extract titles from the Name column using the above function `get_title`. Hint: Use built-in [`map()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function. The syntax is `df['New_column'] = df['Relevant_column'].map(function_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us peek into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the unique values for the titles along with their frequency. Hint: Use an inbuilt pandas function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to replace the various spellings of the same title to a single one. Hint: Use the below dictionary with the [`replace`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) function\n",
    "\n",
    "`title_dictionary = {'Ms.': 'Miss.', 'Mlle.': 'Miss.', \n",
    "              'Dr.': 'Rare', 'Mme.': 'Mrs.', \n",
    "              'Major.': 'Rare', 'Lady.': 'Rare', \n",
    "              'Sir.': 'Rare', 'Col.': 'Rare', \n",
    "              'Capt.': 'Rare', 'Countess.': 'Rare', \n",
    "              'Jonkheer.': 'Rare', 'Dona.': 'Rare', \n",
    "              'Don.': 'Rare', 'Rev.': 'Rare'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the unique values for the titles along with their frequency to check that the titles are replaced properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers? Hint: Use the inbuilt function [`median`](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers with the title 'Miss.'? Hint: Use [`loc[]`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) method for slicing off the select rows and the *Age* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median age of passengers with the title 'Mrs.'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a noticeble difference in the median ages for the passengers with the above two titles? Should we take titles into account while filling the missing values for the *Age* column? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the exercise session. If you finished early, move on to the next section for merging datasets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merging columns from different datasets (Optional) <a name=\"section4\"></a>:\n",
    "A simple illustration to merge two datasets using [`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'CourseCode': ['PHYS024', 'CSCI35', 'ENGR156'], \n",
    "                   'CourseName': ['Mechanics and Wave Motion', \n",
    "                                  'Computer Science for Insight',\n",
    "                                 'Intro to Comm & Info Theory']})\n",
    "\n",
    "df2 = pd.DataFrame({'Professor': ['Zachary Dodds', 'Vatche Sahakian', \n",
    "                                  'Timothy Tsai', 'Brian Shuve'],\n",
    "                    'CourseCode': ['CSCI35', 'PHYS024',  'ENGR156', 'PHYS024']})\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df2, df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to the documents [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to better grasp how and when to use `merge()` function. \n",
    "\n",
    "#### Merging dataframes from [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/overview) dataset:\n",
    "Our next dataset is taken from a [competition](https://www.kaggle.com/c/instacart-market-basket-analysis/overview) hosted by Instacard on Kaggle platform. The dataset contains information about products in its grocery stores given in four files. Please see [here](https://www.kaggle.com/c/instacart-market-basket-analysis/data) for more information.\n",
    "We load the four files into separate dataframes:   \n",
    "`aisles.csv`   \n",
    "`departments.csv`  \n",
    "`products.csv`  \n",
    "`order_products__train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/instacart-market-basket-analysis/'\n",
    "dfa = pd.read_csv(path + 'aisles.csv')\n",
    "dfd = pd.read_csv(path + 'departments.csv')\n",
    "dfp = pd.read_csv(path + 'products.csv')\n",
    "dfo = pd.read_csv(path + 'order_products__train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Familiarize yourself with the dataframes. Hint: Use [`head()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html).  \n",
    "Note: You might want to add the code cells. This can be done in two ways:\n",
    "1. Using the keyboard shortcuts: \n",
    "    1. First press `Esc` key to enter the command mode.\n",
    "    2. Add cell above using `A` or below using `B`.\n",
    "    3. Exit by pressing `Enter/Return` key.\n",
    "2. Using `Insert` tab in the top bar of the notebook and then `Insert Cell Above` or `Insert Cell Below`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal: Get a dataframe consisting of the name of the products along with their aisle names and department names for the order with `order_id` equal to 1.**  \n",
    "This dataframe must have ***8 rows and only three columns:\n",
    "```'product_name', 'aisle', 'department'```***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First slice out 8 rows from the order_products dataframe that corresponds with `order_id` equal to 1 and save it in a new dataframe `df`. Hint: Use conditional on indexing as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a peek into the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe `df` has a column named `product_id`. So, we can merge it with the dataframe `dfp` to get `product_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the dataframes `df` and `dfp` using [`merge()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) and save the result back to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether the new columns are added to the dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have new columns `aisle_id` and `department_id`. Let us first merge `dfa` with this dataframe to get the column `aisle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check our dataframe `df` again. It should reflect the changes we attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should have the column `aisle`. Let us now merge `dfd` with this dataframe to get the column `department`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the dataframe `df` again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we only select 3 columns: `'product_name', 'aisle', 'department'`. Hint: Use indexing with the list of columns as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the dataframe `df` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the shape of th dataframe `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be `(8, 3)`. Please check your code above if you get something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgment:\n",
    "* [Titanic dataset from Kaggle](https://www.kaggle.com/c/titanic) dataset openly available in Kaggle is used in the exercises.\n",
    "* [Instacart Market Basket Analysis](https://www.kaggle.com/c/instacart-market-basket-analysis/data) dataset openly available in Kaggle is used in the exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
